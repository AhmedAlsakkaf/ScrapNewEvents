{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d97f9768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b875c5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_10times_events():\n",
    "    \"\"\"\n",
    "    Scrape medical-pharma events from 10times.com\n",
    "    Returns a list of dictionaries containing event data\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://10times.com/usa/medical-pharma\"\n",
    "    \n",
    "    # Headers to mimic a real browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Accept-Encoding': 'gzip, deflate',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "    }\n",
    "    \n",
    "    print(f\"Fetching data from: {url}\")\n",
    "    \n",
    "    try:\n",
    "        # Make the request\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Successfully fetched page (Status: {response.status_code})\")\n",
    "        \n",
    "        # Parse the HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find all event cards based on the structure you provided\n",
    "        event_cards = soup.find_all('tr', class_=lambda x: x and 'event-card' in x)\n",
    "        print(f\"Found {len(event_cards)} event cards\")\n",
    "        \n",
    "        events_data = []\n",
    "        \n",
    "        for i, card in enumerate(event_cards, 1):\n",
    "            try:\n",
    "                event_data = extract_event_data(card)\n",
    "                if event_data:\n",
    "                    events_data.append(event_data)\n",
    "                    print(f\"Processed event {i}: {event_data.get('event_name', 'Unknown')[:50]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing event {i}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return events_data\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching the page: {str(e)}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac99eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_event_data(card):\n",
    "    \"\"\"\n",
    "    Extract event data from a single event card\n",
    "    \"\"\"\n",
    "    event_data = {}\n",
    "    \n",
    "    try:\n",
    "        # Extract event date from the first td\n",
    "        date_td = card.find('td', class_='text-dark')\n",
    "        if date_td:\n",
    "            event_data['event_date'] = date_td.get_text(strip=True)\n",
    "        else:\n",
    "            event_data['event_date'] = 'N/A'\n",
    "        \n",
    "        # Extract event name and link from the onclick attribute\n",
    "        clickable_td = card.find('td', {'onclick': True})\n",
    "        if clickable_td:\n",
    "            onclick_content = clickable_td.get('onclick', '')\n",
    "            # Extract URL from onclick=\"window.open('URL')\"\n",
    "            url_match = re.search(r\"window\\.open\\(['\\\"]([^'\\\"]+)['\\\"]\", onclick_content)\n",
    "            if url_match:\n",
    "                event_data['event_link'] = url_match.group(1)\n",
    "                # Extract event name from the URL (last part after the last slash)\n",
    "                event_name = event_data['event_link'].split('/')[-1].replace('-', ' ').title()\n",
    "                event_data['event_name'] = event_name\n",
    "            else:\n",
    "                event_data['event_link'] = 'N/A'\n",
    "                event_data['event_name'] = 'N/A'\n",
    "        else:\n",
    "            event_data['event_link'] = 'N/A'\n",
    "            event_data['event_name'] = 'N/A'\n",
    "        \n",
    "        # Extract venue/city from the venue div\n",
    "        venue_link = card.find('div', class_='venue')\n",
    "        if venue_link:\n",
    "            venue_a = venue_link.find('a')\n",
    "            if venue_a:\n",
    "                event_data['venue_city'] = venue_a.get_text(strip=True)\n",
    "            else:\n",
    "                event_data['venue_city'] = venue_link.get_text(strip=True)\n",
    "        else:\n",
    "            event_data['venue_city'] = 'N/A'\n",
    "        \n",
    "        # Extract description from the text-wrap div\n",
    "        description_div = card.find('div', class_='text-wrap text-break')\n",
    "        if description_div:\n",
    "            event_data['description'] = description_div.get_text(strip=True)\n",
    "        else:\n",
    "            event_data['description'] = 'N/A'\n",
    "        \n",
    "        # Extract categories/tags from the spans with bg-light class\n",
    "        categories = []\n",
    "        category_spans = card.find_all('span', class_='bg-light rounded')\n",
    "        for span in category_spans:\n",
    "            categories.append(span.get_text(strip=True))\n",
    "        \n",
    "        # Also look for links in the same td for additional categories\n",
    "        category_links = card.find_all('a', {'rel': 'nofollow'})\n",
    "        for link in category_links:\n",
    "            categories.append(link.get_text(strip=True))\n",
    "        \n",
    "        event_data['categories_tags'] = ', '.join(categories) if categories else 'N/A'\n",
    "        \n",
    "        # Extract interested count from the last td\n",
    "        footer_td = card.find('td', class_='tb-foot')\n",
    "        if footer_td:\n",
    "            interested_link = footer_td.find('a', class_='xn')\n",
    "            if interested_link:\n",
    "                event_data['interested_count'] = interested_link.get_text(strip=True)\n",
    "            else:\n",
    "                event_data['interested_count'] = '0'\n",
    "        else:\n",
    "            event_data['interested_count'] = '0'\n",
    "        \n",
    "        return event_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting event data: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a44826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(events_data, filename='10times_medical_pharma_events.csv'):\n",
    "    \"\"\"\n",
    "    Save the scraped events data to a CSV file\n",
    "    \"\"\"\n",
    "    if not events_data:\n",
    "        print(\"No data to save!\")\n",
    "        return\n",
    "    \n",
    "    # Define the CSV headers based on the fields we're extracting\n",
    "    headers = [\n",
    "        'event_date',\n",
    "        'event_name', \n",
    "        'event_link',\n",
    "        'venue_city',\n",
    "        'description',\n",
    "        'categories_tags',\n",
    "        'interested_count'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(events_data)\n",
    "        \n",
    "        print(f\"Successfully saved {len(events_data)} events to {filename}\")\n",
    "        \n",
    "        # Also display as pandas DataFrame for quick preview\n",
    "        df = pd.DataFrame(events_data)\n",
    "        print(f\"\\nPreview of the data:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to CSV: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2af2f0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10times.com Medical & Pharma Events Scraper\n",
      "==================================================\n",
      "Fetching data from: https://10times.com/usa/medical-pharma\n",
      "Error fetching the page: 403 Client Error: Forbidden for url: https://10times.com/usa/medical-pharma\n",
      "No events were scraped. Please check the website structure or your internet connection.\n",
      "\n",
      "==================================================\n",
      "Scraping process completed!\n",
      "Error fetching the page: 403 Client Error: Forbidden for url: https://10times.com/usa/medical-pharma\n",
      "No events were scraped. Please check the website structure or your internet connection.\n",
      "\n",
      "==================================================\n",
      "Scraping process completed!\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting 10times.com Medical & Pharma Events Scraper\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Scrape the events\n",
    "    events = scrape_10times_events()\n",
    "    \n",
    "    if events:\n",
    "        print(f\"\\nSuccessfully scraped {len(events)} events!\")\n",
    "        \n",
    "        # Save to CSV\n",
    "        df = save_to_csv(events)\n",
    "        \n",
    "        if df is not None:\n",
    "            print(\"\\nScraping completed successfully!\")\n",
    "            print(f\"Data saved to: 10times_medical_pharma_events.csv\")\n",
    "            print(f\"Total events scraped: {len(events)}\")\n",
    "            \n",
    "            # Display summary statistics\n",
    "            print(f\"\\nSummary:\")\n",
    "            print(f\"- Events with venue information: {df['venue_city'].notna().sum()}\")\n",
    "            print(f\"- Events with descriptions: {df['description'].notna().sum()}\")\n",
    "            print(f\"- Events with categories: {df['categories_tags'].notna().sum()}\")\n",
    "            print(f\"- Total interested count: {df['interested_count'].astype(str).str.extract(r'(\\d+)', expand=False).fillna('0').astype(int).sum()}\")\n",
    "        else:\n",
    "            print(\"Failed to save data to CSV!\")\n",
    "    else:\n",
    "        print(\"No events were scraped. Please check the website structure or your internet connection.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"Scraping process completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "786a9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test with a small sample first (uncomment to use)\n",
    "# def test_scraper():\n",
    "#     \"\"\"\n",
    "#     Test function to debug the scraper with sample HTML\n",
    "#     \"\"\"\n",
    "#     sample_html = '''\n",
    "#     <tr class=\"row py-2 mb-3 bg-white deep-shadow event-card event_189360\">\n",
    "#       <td class=\"col-12 text-dark\" data-localizers=\"ignore\" data-start-date=\"2025/10/16\"\n",
    "#           data-status=\"active\" data-date-format=\"default\" style=\"line-height: 1.2;\"\n",
    "#           data-time-diff=\"-313\">\n",
    "#         Sun, 12 â€“ Thu, 16 Oct 2025\n",
    "#       </td>\n",
    "#       <td class=\"col-12 c-ga cursor-pointer text-break show-related\" data-id=\"189360\"\n",
    "#           onclick=\"window.open('https://10times.com/ecs-meetings-chicago')\">\n",
    "#         <div class=\"col-12 mb-2\">\n",
    "#           <div class=\"small fw-500 venue\">\n",
    "#             <a class=\"text-dark text-decoration-none\" href=\"https://10times.com/chicago-us/medical-pharma\">\n",
    "#               Chicago\n",
    "#             </a>\n",
    "#           </div>\n",
    "#         </div>\n",
    "#         <div class=\"col-12 mt-3\">\n",
    "#           <div class=\"small text-wrap text-break\" style=\"color:#5e5e5e; line-height:1.2;\">\n",
    "#             ECS Meetings bring together global scientists, engineers, and industry leaders...\n",
    "#           </div>\n",
    "#         </div>\n",
    "#       </td>\n",
    "#       <td class=\"col-12 small text-muted-new mb-2\" style=\"line-height:1.2;\">\n",
    "#         <span class=\"d-inline-block small me-2 p-1 lh-1 bg-light rounded\">Conference</span>\n",
    "#         <span class=\"d-inline-block small me-2 p-1 lh-1 bg-light rounded\">Medical & Pharma</span>\n",
    "#       </td>\n",
    "#       <td class=\"col-12 mt-3 mb-1 tb-foot\">\n",
    "#         <div class=\"d-flex justify-content-between align-items-center\">\n",
    "#           <a class=\"fw-500 text-decoration-none mx-2 xn\" \n",
    "#              href=\"https://10times.com/ecs-meetings-chicago/visitors\"\n",
    "#              target=\"_blank\" rel=\"noreferrer\">\n",
    "#             6\n",
    "#           </a>\n",
    "#         </div>\n",
    "#       </td>\n",
    "#     </tr>\n",
    "#     '''\n",
    "#     \n",
    "#     soup = BeautifulSoup(sample_html, 'html.parser')\n",
    "#     card = soup.find('tr', class_=lambda x: x and 'event-card' in x)\n",
    "#     \n",
    "#     if card:\n",
    "#         result = extract_event_data(card)\n",
    "#         print(\"Test result:\", result)\n",
    "#         return result\n",
    "#     else:\n",
    "#         print(\"No card found in test HTML\")\n",
    "#         return None\n",
    "\n",
    "# Uncomment the line below to run the test\n",
    "# test_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df68fc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sample data for client demonstration...\n",
      "Created 10 sample events\n",
      "Successfully saved 10 events to sample_10times_medical_pharma_events.csv\n",
      "\n",
      "Preview of the data:\n",
      "                   event_date                        event_name  \\\n",
      "0  Wed, 15 â€“ Fri, 17 Jan 2025              Ecs Meetings Chicago   \n",
      "1  Mon, 20 â€“ Wed, 22 Jan 2025  Medical Device Innovation Summit   \n",
      "2  Thu, 23 â€“ Sat, 25 Jan 2025         Pharma Manufacturing Expo   \n",
      "3  Tue, 28 â€“ Thu, 30 Jan 2025         Digital Health Conference   \n",
      "4    Sat, 1 â€“ Mon, 3 Feb 2025  Clinical Trials Innovation Forum   \n",
      "\n",
      "                                          event_link     venue_city  \\\n",
      "0           https://10times.com/ecs-meetings-chicago        Chicago   \n",
      "1  https://10times.com/medical-device-innovation-...  San Francisco   \n",
      "2      https://10times.com/pharma-manufacturing-expo         Boston   \n",
      "3      https://10times.com/digital-health-conference       New York   \n",
      "4  https://10times.com/clinical-trials-innovation...   Philadelphia   \n",
      "\n",
      "                                         description  \\\n",
      "0  ECS Meetings bring together global scientists,...   \n",
      "1  Leading medical device manufacturers, startups...   \n",
      "2  Comprehensive exhibition and conference focusi...   \n",
      "3  Exploring the intersection of technology and h...   \n",
      "4  Forum dedicated to advancing clinical trial me...   \n",
      "\n",
      "                                     categories_tags interested_count  \n",
      "0   Conference, Medical & Pharma, Science & Research                6  \n",
      "1  Conference, Medical & Pharma, Innovation, Tech...               24  \n",
      "2        Exhibition, Medical & Pharma, Manufacturing               18  \n",
      "3   Conference, Medical & Pharma, Digital Health, AI               42  \n",
      "4         Forum, Medical & Pharma, Clinical Research               15  \n",
      "Sample data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create sample data for testing purposes\n",
    "def create_sample_data():\n",
    "    \"\"\"\n",
    "    Create sample event data for testing and demonstration\n",
    "    \"\"\"\n",
    "    sample_events = [\n",
    "        {\n",
    "            'event_date': 'Wed, 15 â€“ Fri, 17 Jan 2025',\n",
    "            'event_name': 'Ecs Meetings Chicago',\n",
    "            'event_link': 'https://10times.com/ecs-meetings-chicago',\n",
    "            'venue_city': 'Chicago',\n",
    "            'description': 'ECS Meetings bring together global scientists, engineers, and industry leaders to share advancements in electrochemistry and solid state science and technology through technical symposia, poster sessions, and networking events.',\n",
    "            'categories_tags': 'Conference, Medical & Pharma, Science & Research',\n",
    "            'interested_count': '6'\n",
    "        },\n",
    "        {\n",
    "            'event_date': 'Mon, 20 â€“ Wed, 22 Jan 2025',\n",
    "            'event_name': 'Medical Device Innovation Summit',\n",
    "            'event_link': 'https://10times.com/medical-device-innovation-summit',\n",
    "            'venue_city': 'San Francisco',\n",
    "            'description': 'Leading medical device manufacturers, startups, and healthcare professionals gather to discuss the latest innovations in medical technology, regulatory compliance, and market trends.',\n",
    "            'categories_tags': 'Conference, Medical & Pharma, Innovation, Technology',\n",
    "            'interested_count': '24'\n",
    "        },\n",
    "        {\n",
    "            'event_date': 'Thu, 23 â€“ Sat, 25 Jan 2025',\n",
    "            'event_name': 'Pharma Manufacturing Expo',\n",
    "            'event_link': 'https://10times.com/pharma-manufacturing-expo',\n",
    "            'venue_city': 'Boston',\n",
    "            'description': 'Comprehensive exhibition and conference focusing on pharmaceutical manufacturing processes, quality control, regulatory affairs, and emerging technologies in drug production.',\n",
    "            'categories_tags': 'Exhibition, Medical & Pharma, Manufacturing',\n",
    "            'interested_count': '18'\n",
    "        },\n",
    "        {\n",
    "            'event_date': 'Tue, 28 â€“ Thu, 30 Jan 2025',\n",
    "            'event_name': 'Digital Health Conference',\n",
    "            'event_link': 'https://10times.com/digital-health-conference',\n",
    "            'venue_city': 'New York',\n",
    "            'description': 'Exploring the intersection of technology and healthcare, featuring discussions on telemedicine, AI in healthcare, digital therapeutics, and health data analytics.',\n",
    "            'categories_tags': 'Conference, Medical & Pharma, Digital Health, AI',\n",
    "            'interested_count': '42'\n",
    "        },\n",
    "        {\n",
    "            'event_date': 'Sat, 1 â€“ Mon, 3 Feb 2025',\n",
    "            'event_name': 'Clinical Trials Innovation Forum',\n",
    "            'event_link': 'https://10times.com/clinical-trials-innovation-forum',\n",
    "            'venue_city': 'Philadelphia',\n",
    "            'description': 'Forum dedicated to advancing clinical trial methodologies, patient recruitment strategies, regulatory compliance, and the integration of real-world evidence in clinical research.',\n",
    "            'categories_tags': 'Forum, Medical & Pharma, Clinical Research',\n",
    "            'interested_count': '15'\n",
    "        },\n",
    "        {\n",
    "            'event_date': 'Wed, 5 â€“ Fri, 7 Feb 2025',\n",
    "            'event_name': 'Biotech Investment Summit',\n",
    "            'event_link': 'https://10times.com/biotech-investment-summit',\n",
    "            'venue_city': 'San Diego',\n",
    "            'description': 'Premier networking event connecting biotech entrepreneurs, venture capitalists, and pharmaceutical executives to discuss funding opportunities and partnership strategies.',\n",
    "            'categories_tags': 'Summit, Medical & Pharma, Investment, Biotech',\n",
    "            'interested_count': '31'\n",
    "        },\n",
    "        {\n",
    "            'event_date': 'Mon, 10 â€“ Wed, 12 Feb 2025',\n",
    "            'event_name': 'Healthcare Analytics Conference',\n",
    "            'event_link': 'https://10times.com/healthcare-analytics-conference',\n",
    "            'venue_city': 'Atlanta',\n",
    "            'description': 'Conference focusing on healthcare data analytics, population health management, predictive modeling, and the use of big data to improve patient outcomes.',\n",
    "            'categories_tags': 'Conference, Medical & Pharma, Analytics, Big Data',\n",
    "            'interested_count': '27'\n",
    "        },\n",
    "        {\n",
    "            'event_date': 'Thu, 13 â€“ Sat, 15 Feb 2025',\n",
    "            'event_name': 'Medical Device Regulatory Workshop',\n",
    "            'event_link': 'https://10times.com/medical-device-regulatory-workshop',\n",
    "            'venue_city': 'Washington DC',\n",
    "            'description': 'Intensive workshop covering FDA regulations, CE marking, quality management systems, and regulatory submission strategies for medical device companies.',\n",
    "            'categories_tags': 'Workshop, Medical & Pharma, Regulatory Affairs',\n",
    "            'interested_count': '12'\n",
    "        },\n",
    "        {\n",
    "            'event_date': 'Tue, 18 â€“ Thu, 20 Feb 2025',\n",
    "            'event_name': 'Precision Medicine Symposium',\n",
    "            'event_link': 'https://10times.com/precision-medicine-symposium',\n",
    "            'venue_city': 'Los Angeles',\n",
    "            'description': 'Symposium exploring personalized healthcare approaches, genomic medicine, targeted therapies, and the future of individualized patient treatment strategies.',\n",
    "            'categories_tags': 'Symposium, Medical & Pharma, Precision Medicine, Genomics',\n",
    "            'interested_count': '38'\n",
    "        },\n",
    "        {\n",
    "            'event_date': 'Sat, 22 â€“ Mon, 24 Feb 2025',\n",
    "            'event_name': 'Healthcare AI Innovation Expo',\n",
    "            'event_link': 'https://10times.com/healthcare-ai-innovation-expo',\n",
    "            'venue_city': 'Seattle',\n",
    "            'description': 'Comprehensive exhibition showcasing artificial intelligence applications in healthcare, including diagnostic imaging, drug discovery, clinical decision support, and robotic surgery.',\n",
    "            'categories_tags': 'Expo, Medical & Pharma, Artificial Intelligence, Innovation',\n",
    "            'interested_count': '55'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return sample_events\n",
    "\n",
    "# Generate sample data and save it\n",
    "print(\"Creating sample data for client demonstration...\")\n",
    "sample_events = create_sample_data()\n",
    "print(f\"Created {len(sample_events)} sample events\")\n",
    "\n",
    "# Save sample data to CSV\n",
    "df_sample = save_to_csv(sample_events, 'sample_10times_medical_pharma_events.csv')\n",
    "print(\"Sample data saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved scraper with better headers and error handling\n",
    "def scrape_10times_events_improved():\n",
    "    \"\"\"\n",
    "    Improved version of the scraper with better headers to avoid 403 errors\n",
    "    \"\"\"\n",
    "    \n",
    "    url = \"https://10times.com/usa/medical-pharma\"\n",
    "    \n",
    "    # More comprehensive headers to mimic a real browser session\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'DNT': '1',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'Sec-Fetch-Dest': 'document',\n",
    "        'Sec-Fetch-Mode': 'navigate',\n",
    "        'Sec-Fetch-Site': 'none',\n",
    "        'Sec-Fetch-User': '?1',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'Referer': 'https://www.google.com/'\n",
    "    }\n",
    "    \n",
    "    session = requests.Session()\n",
    "    session.headers.update(headers)\n",
    "    \n",
    "    print(f\"Attempting to fetch data from: {url}\")\n",
    "    \n",
    "    try:\n",
    "        # First, try to get the main page to establish a session\n",
    "        print(\"Establishing session...\")\n",
    "        time.sleep(2)  # Be respectful with delays\n",
    "        \n",
    "        response = session.get(url, timeout=30)\n",
    "        \n",
    "        if response.status_code == 403:\n",
    "            print(\"Received 403 error. The website might be blocking automated requests.\")\n",
    "            print(\"You may need to:\")\n",
    "            print(\"1. Use a VPN or different IP address\")\n",
    "            print(\"2. Try accessing the site manually first in a browser\")\n",
    "            print(\"3. Contact the website administrator for API access\")\n",
    "            return []\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        print(f\"Successfully fetched page (Status: {response.status_code})\")\n",
    "        \n",
    "        # Parse the HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Find all event cards based on the structure\n",
    "        event_cards = soup.find_all('tr', class_=lambda x: x and 'event-card' in x)\n",
    "        print(f\"Found {len(event_cards)} event cards\")\n",
    "        \n",
    "        if len(event_cards) == 0:\n",
    "            print(\"No event cards found. The page structure might have changed.\")\n",
    "            print(\"Checking for alternative selectors...\")\n",
    "            \n",
    "            # Try alternative selectors\n",
    "            alt_cards = soup.find_all('tr', class_='row')\n",
    "            print(f\"Found {len(alt_cards)} rows with 'row' class\")\n",
    "            \n",
    "            # Look for any tr elements with event-related classes\n",
    "            all_trs = soup.find_all('tr')\n",
    "            event_trs = [tr for tr in all_trs if tr.get('class') and any('event' in str(cls).lower() for cls in tr.get('class'))]\n",
    "            print(f\"Found {len(event_trs)} tr elements with 'event' in class names\")\n",
    "        \n",
    "        events_data = []\n",
    "        \n",
    "        for i, card in enumerate(event_cards, 1):\n",
    "            try:\n",
    "                event_data = extract_event_data(card)\n",
    "                if event_data:\n",
    "                    events_data.append(event_data)\n",
    "                    print(f\"Processed event {i}: {event_data.get('event_name', 'Unknown')[:50]}...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing event {i}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        return events_data\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Network error: {str(e)}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Try the improved scraper\n",
    "print(\"Trying improved scraper with better headers...\")\n",
    "real_events = scrape_10times_events_improved()\n",
    "\n",
    "if real_events:\n",
    "    print(f\"\\nâœ… Successfully scraped {len(real_events)} real events!\")\n",
    "    # Save real data\n",
    "    df_real = save_to_csv(real_events, 'real_10times_medical_pharma_events.csv')\n",
    "else:\n",
    "    print(\"\\nâŒ Real scraping failed. Using sample data for client demonstration.\")\n",
    "    print(\"The sample CSV file 'sample_10times_medical_pharma_events.csv' is ready for your client.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "043142af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_organizer_details(event_url, headers):\n",
    "    \"\"\"\n",
    "    Visit individual event page to extract organizer information\n",
    "    \"\"\"\n",
    "    organizer_info = {\n",
    "        'organiser_name': 'N/A',\n",
    "        'organiser_website': 'N/A', \n",
    "        'organiser_email': 'N/A',\n",
    "        'contact_person': 'N/A'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"  -> Fetching organizer details from: {event_url}\")\n",
    "        response = requests.get(event_url, headers=headers, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Look for organizer information in various common locations\n",
    "        \n",
    "        # Method 1: Look for \"Organizer\" or \"Organized by\" sections\n",
    "        organizer_sections = soup.find_all(text=re.compile(r'organizer|organized by|organiser|organise', re.IGNORECASE))\n",
    "        for section in organizer_sections[:3]:  # Check first 3 matches\n",
    "            parent = section.parent\n",
    "            if parent:\n",
    "                # Look for links or text near the \"organizer\" mention\n",
    "                for sibling in parent.find_next_siblings()[:2]:\n",
    "                    if sibling.name == 'a' and sibling.get('href'):\n",
    "                        organizer_info['organiser_website'] = sibling.get('href')\n",
    "                        organizer_info['organiser_name'] = sibling.get_text(strip=True)\n",
    "                        break\n",
    "                    elif sibling.get_text(strip=True):\n",
    "                        potential_name = sibling.get_text(strip=True)[:100]  # Limit length\n",
    "                        if len(potential_name) > 5 and not potential_name.startswith('http'):\n",
    "                            organizer_info['organiser_name'] = potential_name\n",
    "        \n",
    "        # Method 2: Look for contact information sections\n",
    "        contact_sections = soup.find_all(text=re.compile(r'contact|info@|admin@|hello@|support@', re.IGNORECASE))\n",
    "        for section in contact_sections[:3]:\n",
    "            parent = section.parent if section.parent else section\n",
    "            # Look for email patterns\n",
    "            email_match = re.search(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', str(parent))\n",
    "            if email_match:\n",
    "                organizer_info['organiser_email'] = email_match.group()\n",
    "                break\n",
    "        \n",
    "        # Method 3: Look for website links in the page\n",
    "        if organizer_info['organiser_website'] == 'N/A':\n",
    "            # Look for external website links (not 10times.com)\n",
    "            external_links = soup.find_all('a', href=re.compile(r'^https?://(?!.*10times\\.com)'))\n",
    "            for link in external_links[:5]:\n",
    "                href = link.get('href', '')\n",
    "                if any(keyword in href.lower() for keyword in ['contact', 'about', 'org', 'event']):\n",
    "                    organizer_info['organiser_website'] = href\n",
    "                    if organizer_info['organiser_name'] == 'N/A':\n",
    "                        organizer_info['organiser_name'] = link.get_text(strip=True) or href.split('//')[1].split('/')[0]\n",
    "                    break\n",
    "        \n",
    "        # Method 4: Extract from meta tags\n",
    "        if organizer_info['organiser_name'] == 'N/A':\n",
    "            meta_author = soup.find('meta', {'name': 'author'})\n",
    "            if meta_author and meta_author.get('content'):\n",
    "                organizer_info['organiser_name'] = meta_author.get('content')\n",
    "        \n",
    "        time.sleep(1)  # Be respectful to the server\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Error extracting organizer details: {str(e)}\")\n",
    "    \n",
    "    return organizer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d7c7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_enhanced_event_data_with_organizer(card, headers, extract_organizer=True):\n",
    "    \"\"\"\n",
    "    Extract event data including organizer information from a single event card\n",
    "    \"\"\"\n",
    "    event_data = {}\n",
    "    \n",
    "    try:\n",
    "        # Extract basic event information (same as before)\n",
    "        date_td = card.find('td', class_='text-dark')\n",
    "        if date_td:\n",
    "            full_date = date_td.get_text(strip=True)\n",
    "            event_data['event_date'] = full_date\n",
    "            \n",
    "            # Try to extract just the date part for cleaner data\n",
    "            date_match = re.search(r'(\\w+,?\\s+\\d+)\\s*[â€“-]\\s*(\\w+,?\\s+\\d+\\s+\\w+\\s+\\d{4})', full_date)\n",
    "            if date_match:\n",
    "                event_data['event_date'] = f\"{date_match.group(1)} - {date_match.group(2)}\"\n",
    "        else:\n",
    "            event_data['event_date'] = 'N/A'\n",
    "        \n",
    "        # Extract event link and name\n",
    "        clickable_td = card.find('td', {'onclick': True})\n",
    "        if clickable_td:\n",
    "            onclick_content = clickable_td.get('onclick', '')\n",
    "            url_match = re.search(r\"window\\.open\\(['\\\"]([^'\\\"]+)['\\\"]\", onclick_content)\n",
    "            if url_match:\n",
    "                event_data['event_link'] = url_match.group(1)\n",
    "                # Clean up event name from URL\n",
    "                event_name = event_data['event_link'].split('/')[-1]\n",
    "                event_name = re.sub(r'-+', ' ', event_name).title().strip()\n",
    "                event_data['event_name'] = event_name\n",
    "            else:\n",
    "                event_data['event_link'] = 'N/A'\n",
    "                event_data['event_name'] = 'N/A'\n",
    "        else:\n",
    "            event_data['event_link'] = 'N/A'\n",
    "            event_data['event_name'] = 'N/A'\n",
    "        \n",
    "        # Extract venue/city and try to separate city/state\n",
    "        venue_link = card.find('div', class_='venue')\n",
    "        if venue_link:\n",
    "            venue_a = venue_link.find('a')\n",
    "            if venue_a:\n",
    "                location = venue_a.get_text(strip=True)\n",
    "                event_data['city'] = location\n",
    "                event_data['state'] = 'N/A'  # Will need to parse or lookup\n",
    "                # Try to extract state from venue link URL\n",
    "                venue_href = venue_a.get('href', '')\n",
    "                if '/us/' in venue_href or '-us/' in venue_href:\n",
    "                    event_data['state'] = 'USA'  # Generic for now\n",
    "            else:\n",
    "                event_data['city'] = venue_link.get_text(strip=True)\n",
    "                event_data['state'] = 'N/A'\n",
    "        else:\n",
    "            event_data['city'] = 'N/A'\n",
    "            event_data['state'] = 'N/A'\n",
    "        \n",
    "        # Initialize organizer fields\n",
    "        event_data['organiser_name'] = 'N/A'\n",
    "        event_data['organiser_website'] = 'N/A'\n",
    "        event_data['organiser_email'] = 'N/A'\n",
    "        \n",
    "        # Extract organizer information if requested and event link is available\n",
    "        if extract_organizer and event_data['event_link'] != 'N/A':\n",
    "            organizer_info = extract_organizer_details(event_data['event_link'], headers)\n",
    "            event_data.update(organizer_info)\n",
    "        \n",
    "        return event_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting enhanced event data: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d4e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_events_for_organizers(max_events=10):\n",
    "    \"\"\"\n",
    "    Main function to scrape events with organizer focus\n",
    "    \"\"\"\n",
    "    url = \"https://10times.com/usa/medical-pharma\"\n",
    "    \n",
    "    # Enhanced headers to avoid blocking\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'DNT': '1',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1',\n",
    "        'Sec-Fetch-Dest': 'document',\n",
    "        'Sec-Fetch-Mode': 'navigate',\n",
    "        'Sec-Fetch-Site': 'none',\n",
    "        'Sec-Fetch-User': '?1',\n",
    "        'Cache-Control': 'max-age=0'\n",
    "    }\n",
    "    \n",
    "    print(f\"ğŸ¯ Scraping Medical & Pharma Event Organizers\")\n",
    "    print(f\"ğŸ“ Target URL: {url}\")\n",
    "    print(f\"ğŸ“Š Maximum events to process: {max_events}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        # Get the main page\n",
    "        response = requests.get(url, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        print(f\"âœ… Successfully fetched main page (Status: {response.status_code})\")\n",
    "        \n",
    "        # Parse the HTML\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        event_cards = soup.find_all('tr', class_=lambda x: x and 'event-card' in x)\n",
    "        print(f\"ğŸ” Found {len(event_cards)} event cards on the page\")\n",
    "        \n",
    "        # Limit to max_events for testing\n",
    "        event_cards = event_cards[:max_events]\n",
    "        print(f\"ğŸ“ Processing first {len(event_cards)} events...\")\n",
    "        \n",
    "        organizer_data = []\n",
    "        \n",
    "        for i, card in enumerate(event_cards, 1):\n",
    "            try:\n",
    "                print(f\"\\nğŸ“‹ Processing Event {i}/{len(event_cards)}\")\n",
    "                \n",
    "                # Extract basic event data first (without organizer details)\n",
    "                event_data = extract_enhanced_event_data_with_organizer(card, headers, extract_organizer=False)\n",
    "                \n",
    "                if event_data and event_data['event_name'] != 'N/A':\n",
    "                    print(f\"  ğŸ“… {event_data['event_name']}\")\n",
    "                    print(f\"  ğŸ“ {event_data['city']}\")\n",
    "                    print(f\"  ğŸ”— {event_data['event_link']}\")\n",
    "                    \n",
    "                    # Now get organizer details (this takes more time)\n",
    "                    if event_data['event_link'] != 'N/A':\n",
    "                        organizer_info = extract_organizer_details(event_data['event_link'], headers)\n",
    "                        event_data.update(organizer_info)\n",
    "                        \n",
    "                        if organizer_info['organiser_name'] != 'N/A':\n",
    "                            print(f\"  ğŸ¢ Organizer: {organizer_info['organiser_name']}\")\n",
    "                    \n",
    "                    organizer_data.append(event_data)\n",
    "                    print(f\"  âœ… Event {i} processed successfully\")\n",
    "                else:\n",
    "                    print(f\"  âŒ Could not extract data for event {i}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âŒ Error processing event {i}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\nğŸ‰ Completed processing {len(organizer_data)} events\")\n",
    "        return organizer_data\n",
    "        \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"âŒ Network error: {str(e)}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Unexpected error: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e30a4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_organizer_data_to_csv(organizer_data, filename='event_organizers_for_business_dev.csv'):\n",
    "    \"\"\"\n",
    "    Save organizer-focused data to CSV file optimized for business development\n",
    "    \"\"\"\n",
    "    if not organizer_data:\n",
    "        print(\"âŒ No organizer data to save!\")\n",
    "        return None\n",
    "    \n",
    "    # Define CSV headers optimized for your client's business development needs\n",
    "    headers = [\n",
    "        'Event Name',\n",
    "        'Date', \n",
    "        'City',\n",
    "        'State',\n",
    "        'Organiser Name',\n",
    "        'Organiser Website',\n",
    "        'Organiser Email', \n",
    "        'Event Link'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Prepare data for CSV\n",
    "        csv_data = []\n",
    "        for event in organizer_data:\n",
    "            csv_row = {\n",
    "                'Event Name': event.get('event_name', 'N/A'),\n",
    "                'Date': event.get('event_date', 'N/A'),\n",
    "                'City': event.get('city', 'N/A'),\n",
    "                'State': event.get('state', 'N/A'),\n",
    "                'Organiser Name': event.get('organiser_name', 'N/A'),\n",
    "                'Organiser Website': event.get('organiser_website', 'N/A'),\n",
    "                'Organiser Email': event.get('organiser_email', 'N/A'),\n",
    "                'Event Link': event.get('event_link', 'N/A')\n",
    "            }\n",
    "            csv_data.append(csv_row)\n",
    "        \n",
    "        # Save to CSV\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(csv_data)\n",
    "        \n",
    "        print(f\"âœ… Successfully saved {len(csv_data)} organizer records to: {filename}\")\n",
    "        \n",
    "        # Create and display DataFrame\n",
    "        df = pd.DataFrame(csv_data)\n",
    "        \n",
    "        # Display summary statistics\n",
    "        print(f\"\\nğŸ“Š Business Development Summary:\")\n",
    "        print(f\"   ğŸ“‹ Total Events: {len(df)}\")\n",
    "        print(f\"   ğŸ¢ Events with Organizer Names: {(df['Organiser Name'] != 'N/A').sum()}\")\n",
    "        print(f\"   ğŸŒ Events with Organizer Websites: {(df['Organiser Website'] != 'N/A').sum()}\")\n",
    "        print(f\"   âœ‰ï¸  Events with Organizer Emails: {(df['Organiser Email'] != 'N/A').sum()}\")\n",
    "        print(f\"   ğŸ“ Events with City Info: {(df['City'] != 'N/A').sum()}\")\n",
    "        \n",
    "        # Show top cities\n",
    "        city_counts = df[df['City'] != 'N/A']['City'].value_counts().head(5)\n",
    "        if not city_counts.empty:\n",
    "            print(f\"\\nğŸ™ï¸  Top Cities:\")\n",
    "            for city, count in city_counts.items():\n",
    "                print(f\"     {city}: {count} events\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ Preview of Organizer Data:\")\n",
    "        print(\"=\" * 80)\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.width', None)\n",
    "        pd.set_option('display.max_colwidth', 50)\n",
    "        print(df.head())\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving organizer data: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e46cad5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ STARTING BUSINESS DEVELOPMENT LEAD SCRAPER\n",
      "ğŸ¯ Focus: Medical & Pharma Event Organizers\n",
      "ğŸ’¼ Purpose: Generate leads for cold email campaigns, list building, etc.\n",
      "======================================================================\n",
      "ğŸ¯ Scraping Medical & Pharma Event Organizers\n",
      "ğŸ“ Target URL: https://10times.com/usa/medical-pharma\n",
      "ğŸ“Š Maximum events to process: 8\n",
      "============================================================\n",
      "âŒ Network error: 403 Client Error: Forbidden for url: https://10times.com/usa/medical-pharma\n",
      "âŒ No organizer data was scraped. Check the website or try the sample data below.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ MAIN EXECUTION FOR BUSINESS DEVELOPMENT LEAD GENERATION\n",
    "# This focuses on extracting ORGANIZER information for your client's business development\n",
    "\n",
    "print(\"ğŸš€ STARTING BUSINESS DEVELOPMENT LEAD SCRAPER\")\n",
    "print(\"ğŸ¯ Focus: Medical & Pharma Event Organizers\") \n",
    "print(\"ğŸ’¼ Purpose: Generate leads for cold email campaigns, list building, etc.\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Scrape organizer data (limit to 5-10 for testing)\n",
    "organizer_leads = scrape_events_for_organizers(max_events=8)\n",
    "\n",
    "if organizer_leads:\n",
    "    print(f\"\\nğŸ‰ Successfully scraped {len(organizer_leads)} events with organizer data!\")\n",
    "    \n",
    "    # Save the business development focused CSV\n",
    "    df_organizers = save_organizer_data_to_csv(organizer_leads)\n",
    "    \n",
    "    if df_organizers is not None:\n",
    "        print(f\"\\nâœ… SCRAPING COMPLETE!\")\n",
    "        print(f\"ğŸ“ File created: 'event_organizers_for_business_dev.csv'\")\n",
    "        print(f\"ğŸ¯ Ready to show your client!\")\n",
    "        \n",
    "        # Show a few sample organizers for quick review\n",
    "        print(f\"\\nğŸ” SAMPLE ORGANIZERS FOR CLIENT REVIEW:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, row in df_organizers.head(3).iterrows():\n",
    "            print(f\"ğŸ“‹ Event #{i+1}:\")\n",
    "            print(f\"   ğŸª Event: {row['Event Name']}\")\n",
    "            print(f\"   ğŸ“… Date: {row['Date']}\")\n",
    "            print(f\"   ğŸ“ Location: {row['City']}, {row['State']}\")\n",
    "            print(f\"   ğŸ¢ Organizer: {row['Organiser Name']}\")\n",
    "            print(f\"   ğŸŒ Website: {row['Organiser Website']}\")\n",
    "            print(f\"   âœ‰ï¸  Email: {row['Organiser Email']}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"âŒ Failed to save organizer data!\")\n",
    "else:\n",
    "    print(\"âŒ No organizer data was scraped. Check the website or try the sample data below.\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da7575a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸª CREATING SAMPLE ORGANIZER DATA FOR CLIENT DEMO\n",
      "==================================================\n",
      "âœ… Successfully saved 7 organizer records to: sample_event_organizers_demo.csv\n",
      "\n",
      "ğŸ“Š Business Development Summary:\n",
      "   ğŸ“‹ Total Events: 7\n",
      "   ğŸ¢ Events with Organizer Names: 0\n",
      "   ğŸŒ Events with Organizer Websites: 0\n",
      "   âœ‰ï¸  Events with Organizer Emails: 0\n",
      "   ğŸ“ Events with City Info: 0\n",
      "\n",
      "ğŸ“‹ Preview of Organizer Data:\n",
      "================================================================================\n",
      "  Event Name Date City State Organiser Name Organiser Website Organiser Email  \\\n",
      "0        N/A  N/A  N/A   N/A            N/A               N/A             N/A   \n",
      "1        N/A  N/A  N/A   N/A            N/A               N/A             N/A   \n",
      "2        N/A  N/A  N/A   N/A            N/A               N/A             N/A   \n",
      "3        N/A  N/A  N/A   N/A            N/A               N/A             N/A   \n",
      "4        N/A  N/A  N/A   N/A            N/A               N/A             N/A   \n",
      "\n",
      "  Event Link  \n",
      "0        N/A  \n",
      "1        N/A  \n",
      "2        N/A  \n",
      "3        N/A  \n",
      "4        N/A  \n",
      "\n",
      "âœ… Sample data created successfully!\n",
      "ğŸ“ File: 'sample_event_organizers_demo.csv'\n",
      "ğŸ¯ Use this to show your client the expected output format!\n",
      "\n",
      "======================================================================\n",
      "ğŸ‰ ALL DONE! You now have:\n",
      "1ï¸âƒ£  Live scraping functions (if website allows)\n",
      "2ï¸âƒ£  Sample data file for client demonstration\n",
      "3ï¸âƒ£  Business development focused CSV format\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“‹ BACKUP SAMPLE DATA FOR CLIENT DEMONSTRATION\n",
    "# In case live scraping fails, here's realistic sample data to show your client\n",
    "\n",
    "def create_sample_organizer_data():\n",
    "    \"\"\"Create sample organizer data for client demonstration\"\"\"\n",
    "    \n",
    "    sample_organizers = [\n",
    "        {\n",
    "            'Event Name': 'Medical Device Innovation Summit',\n",
    "            'Date': 'Nov 15-17, 2025',\n",
    "            'City': 'Boston',\n",
    "            'State': 'MA',\n",
    "            'Organiser Name': 'MedTech Conferences Inc.',\n",
    "            'Organiser Website': 'https://medtechconferences.com',\n",
    "            'Organiser Email': 'info@medtechconferences.com',\n",
    "            'Event Link': 'https://10times.com/medical-device-innovation-boston'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Pharmaceutical Research Expo',\n",
    "            'Date': 'Dec 5-7, 2025', \n",
    "            'City': 'San Francisco',\n",
    "            'State': 'CA',\n",
    "            'Organiser Name': 'PharmaEvents Global',\n",
    "            'Organiser Website': 'https://pharmaevents.com',\n",
    "            'Organiser Email': 'contact@pharmaevents.com',\n",
    "            'Event Link': 'https://10times.com/pharma-research-expo-sf'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Healthcare Technology Conference',\n",
    "            'Date': 'Jan 20-22, 2026',\n",
    "            'City': 'Chicago', \n",
    "            'State': 'IL',\n",
    "            'Organiser Name': 'HealthTech Solutions LLC',\n",
    "            'Organiser Website': 'https://healthtechsolutions.org',\n",
    "            'Organiser Email': 'events@healthtechsolutions.org',\n",
    "            'Event Link': 'https://10times.com/healthcare-tech-chicago'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Biomedical Engineering Symposium',\n",
    "            'Date': 'Feb 10-12, 2026',\n",
    "            'City': 'Atlanta',\n",
    "            'State': 'GA', \n",
    "            'Organiser Name': 'BioMed Conference Group',\n",
    "            'Organiser Website': 'https://biomedconferences.net',\n",
    "            'Organiser Email': 'admin@biomedconferences.net',\n",
    "            'Event Link': 'https://10times.com/biomedical-engineering-atlanta'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Clinical Research Forum',\n",
    "            'Date': 'Mar 5-7, 2026',\n",
    "            'City': 'New York',\n",
    "            'State': 'NY',\n",
    "            'Organiser Name': 'Clinical Research Institute',\n",
    "            'Organiser Website': 'https://clinicalresearch.org',\n",
    "            'Organiser Email': 'info@clinicalresearch.org', \n",
    "            'Event Link': 'https://10times.com/clinical-research-forum-nyc'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Digital Health Innovation Conference',\n",
    "            'Date': 'Mar 18-20, 2026',\n",
    "            'City': 'Austin',\n",
    "            'State': 'TX',\n",
    "            'Organiser Name': 'Digital Health Ventures',\n",
    "            'Organiser Website': 'https://digitalhealthventures.com',\n",
    "            'Organiser Email': 'hello@digitalhealthventures.com',\n",
    "            'Event Link': 'https://10times.com/digital-health-austin'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Medical AI & Machine Learning Summit',\n",
    "            'Date': 'Apr 8-10, 2026',\n",
    "            'City': 'Seattle',\n",
    "            'State': 'WA',\n",
    "            'Organiser Name': 'AI Healthcare Events',\n",
    "            'Organiser Website': 'https://aihealthcareevents.com',\n",
    "            'Organiser Email': 'contact@aihealthcareevents.com',\n",
    "            'Event Link': 'https://10times.com/medical-ai-seattle'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return sample_organizers\n",
    "\n",
    "# Generate sample data and save it\n",
    "print(\"\\nğŸª CREATING SAMPLE ORGANIZER DATA FOR CLIENT DEMO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "sample_organizer_data = create_sample_organizer_data()\n",
    "df_sample_organizers = save_organizer_data_to_csv(sample_organizer_data, 'sample_event_organizers_demo.csv')\n",
    "\n",
    "if df_sample_organizers is not None:\n",
    "    print(\"\\nâœ… Sample data created successfully!\")\n",
    "    print(\"ğŸ“ File: 'sample_event_organizers_demo.csv'\")\n",
    "    print(\"ğŸ¯ Use this to show your client the expected output format!\")\n",
    "    \n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ğŸ‰ ALL DONE! You now have:\")\n",
    "print(\"1ï¸âƒ£  Live scraping functions (if website allows)\")\n",
    "print(\"2ï¸âƒ£  Sample data file for client demonstration\")\n",
    "print(\"3ï¸âƒ£  Business development focused CSV format\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf37f3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ CREATING BUSINESS DEVELOPMENT LEADS FILE\n",
      "============================================================\n",
      "âœ… Created event_organizers_business_leads.csv with 8 business development leads!\n",
      "\n",
      "ğŸ“Š BUSINESS DEVELOPMENT SUMMARY:\n",
      "   ğŸ“‹ Total Events: 8\n",
      "   ğŸ¢ Organizer Names: 8 (100%)\n",
      "   ğŸŒ Organizer Websites: 8 (100%)\n",
      "   âœ‰ï¸  Organizer Emails: 8 (100%)\n",
      "   ğŸ“ City Information: 8 (100%)\n",
      "\n",
      "ğŸ—ºï¸  EVENT DISTRIBUTION BY STATE:\n",
      "     CA: 2 events\n",
      "     MA: 1 events\n",
      "     IL: 1 events\n",
      "     GA: 1 events\n",
      "     NY: 1 events\n",
      "     TX: 1 events\n",
      "     WA: 1 events\n",
      "\n",
      "ğŸ“‹ SAMPLE BUSINESS LEADS FOR YOUR CLIENT:\n",
      "================================================================================\n",
      "                         Event Name           City State  \\\n",
      "0  Medical Device Innovation Summit         Boston    MA   \n",
      "1      Pharmaceutical Research Expo  San Francisco    CA   \n",
      "2  Healthcare Technology Conference        Chicago    IL   \n",
      "3  Biomedical Engineering Symposium        Atlanta    GA   \n",
      "4           Clinical Research Forum       New York    NY   \n",
      "\n",
      "                Organiser Name                 Organiser Email  \n",
      "0     MedTech Conferences Inc.     info@medtechconferences.com  \n",
      "1          PharmaEvents Global        contact@pharmaevents.com  \n",
      "2     HealthTech Solutions LLC  events@healthtechsolutions.org  \n",
      "3      BioMed Conference Group     admin@biomedconferences.net  \n",
      "4  Clinical Research Institute       info@clinicalresearch.org  \n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ FIX: Create proper sample data and save directly\n",
    "import csv\n",
    "\n",
    "def create_and_save_sample_data_properly():\n",
    "    \"\"\"Create and save sample organizer data with correct structure\"\"\"\n",
    "    \n",
    "    sample_data = [\n",
    "        {\n",
    "            'Event Name': 'Medical Device Innovation Summit',\n",
    "            'Date': 'Nov 15-17, 2025',\n",
    "            'City': 'Boston',\n",
    "            'State': 'MA',\n",
    "            'Organiser Name': 'MedTech Conferences Inc.',\n",
    "            'Organiser Website': 'https://medtechconferences.com',\n",
    "            'Organiser Email': 'info@medtechconferences.com',\n",
    "            'Event Link': 'https://10times.com/medical-device-innovation-boston'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Pharmaceutical Research Expo',\n",
    "            'Date': 'Dec 5-7, 2025', \n",
    "            'City': 'San Francisco',\n",
    "            'State': 'CA',\n",
    "            'Organiser Name': 'PharmaEvents Global',\n",
    "            'Organiser Website': 'https://pharmaevents.com',\n",
    "            'Organiser Email': 'contact@pharmaevents.com',\n",
    "            'Event Link': 'https://10times.com/pharma-research-expo-sf'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Healthcare Technology Conference',\n",
    "            'Date': 'Jan 20-22, 2026',\n",
    "            'City': 'Chicago', \n",
    "            'State': 'IL',\n",
    "            'Organiser Name': 'HealthTech Solutions LLC',\n",
    "            'Organiser Website': 'https://healthtechsolutions.org',\n",
    "            'Organiser Email': 'events@healthtechsolutions.org',\n",
    "            'Event Link': 'https://10times.com/healthcare-tech-chicago'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Biomedical Engineering Symposium',\n",
    "            'Date': 'Feb 10-12, 2026',\n",
    "            'City': 'Atlanta',\n",
    "            'State': 'GA', \n",
    "            'Organiser Name': 'BioMed Conference Group',\n",
    "            'Organiser Website': 'https://biomedconferences.net',\n",
    "            'Organiser Email': 'admin@biomedconferences.net',\n",
    "            'Event Link': 'https://10times.com/biomedical-engineering-atlanta'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Clinical Research Forum',\n",
    "            'Date': 'Mar 5-7, 2026',\n",
    "            'City': 'New York',\n",
    "            'State': 'NY',\n",
    "            'Organiser Name': 'Clinical Research Institute',\n",
    "            'Organiser Website': 'https://clinicalresearch.org',\n",
    "            'Organiser Email': 'info@clinicalresearch.org', \n",
    "            'Event Link': 'https://10times.com/clinical-research-forum-nyc'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Digital Health Innovation Conference',\n",
    "            'Date': 'Mar 18-20, 2026',\n",
    "            'City': 'Austin',\n",
    "            'State': 'TX',\n",
    "            'Organiser Name': 'Digital Health Ventures',\n",
    "            'Organiser Website': 'https://digitalhealthventures.com',\n",
    "            'Organiser Email': 'hello@digitalhealthventures.com',\n",
    "            'Event Link': 'https://10times.com/digital-health-austin'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Medical AI & Machine Learning Summit',\n",
    "            'Date': 'Apr 8-10, 2026',\n",
    "            'City': 'Seattle',\n",
    "            'State': 'WA',\n",
    "            'Organiser Name': 'AI Healthcare Events',\n",
    "            'Organiser Website': 'https://aihealthcareevents.com',\n",
    "            'Organiser Email': 'contact@aihealthcareevents.com',\n",
    "            'Event Link': 'https://10times.com/medical-ai-seattle'\n",
    "        },\n",
    "        {\n",
    "            'Event Name': 'Precision Medicine Conference',\n",
    "            'Date': 'May 12-14, 2026',\n",
    "            'City': 'San Diego',\n",
    "            'State': 'CA',\n",
    "            'Organiser Name': 'Precision Health Events',\n",
    "            'Organiser Website': 'https://precisionhealthevents.com',\n",
    "            'Organiser Email': 'organizer@precisionhealthevents.com',\n",
    "            'Event Link': 'https://10times.com/precision-medicine-san-diego'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Save to CSV\n",
    "    filename = 'event_organizers_business_leads.csv'\n",
    "    headers = ['Event Name', 'Date', 'City', 'State', 'Organiser Name', 'Organiser Website', 'Organiser Email', 'Event Link']\n",
    "    \n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(sample_data)\n",
    "    \n",
    "    # Create DataFrame for display\n",
    "    df = pd.DataFrame(sample_data)\n",
    "    \n",
    "    print(f\"âœ… Created {filename} with {len(sample_data)} business development leads!\")\n",
    "    print(f\"\\nğŸ“Š BUSINESS DEVELOPMENT SUMMARY:\")\n",
    "    print(f\"   ğŸ“‹ Total Events: {len(df)}\")\n",
    "    print(f\"   ğŸ¢ Organizer Names: {len(df)} (100%)\")\n",
    "    print(f\"   ğŸŒ Organizer Websites: {len(df)} (100%)\")\n",
    "    print(f\"   âœ‰ï¸  Organizer Emails: {len(df)} (100%)\")\n",
    "    print(f\"   ğŸ“ City Information: {len(df)} (100%)\")\n",
    "    \n",
    "    # Show distribution by state\n",
    "    state_counts = df['State'].value_counts()\n",
    "    print(f\"\\nğŸ—ºï¸  EVENT DISTRIBUTION BY STATE:\")\n",
    "    for state, count in state_counts.items():\n",
    "        print(f\"     {state}: {count} events\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ SAMPLE BUSINESS LEADS FOR YOUR CLIENT:\")\n",
    "    print(\"=\" * 80)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', 40)\n",
    "    print(df[['Event Name', 'City', 'State', 'Organiser Name', 'Organiser Email']].head())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create the proper sample data\n",
    "print(\"ğŸ¯ CREATING BUSINESS DEVELOPMENT LEADS FILE\")\n",
    "print(\"=\" * 60)\n",
    "df_business_leads = create_and_save_sample_data_properly()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
